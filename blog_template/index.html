<html>
<head>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>

<link rel="shortcut icon" href="images/icon.ico">
<style type="text/css">
	body {
		background-color: #f5f9ff;
	}

	/* Hide both math displays initially, will display based on JS detection */
  .mathjax-mobile, .mathml-non-mobile { display: none; }

  /* Show the MathML content by default on non-mobile devices */
  .show-mathml .mathml-non-mobile { display: block; }
  .show-mathjax .mathjax-mobile { display: block; }

	.content-margin-container {
		display: flex;
		width: 100%; /* Ensure the container is full width */
		justify-content: left; /* Horizontally centers the children in the container */
		align-items: center;  /* Vertically centers the children in the container */
	}
	.main-content-block {
		width: 70%; /* Change this percentage as needed */
    max-width: 1100px; /* Optional: Maximum width */
		background-color: #fff;
		border-left: 1px solid #DDD;
		border-right: 1px solid #DDD;
		padding: 8px 8px 8px 8px;
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;#"Avenir";
	}
	.margin-left-block {
			font-size: 14px;
			width: 15%; /* Change this percentage as needed */
			max-width: 130px; /* Optional: Maximum width */
			position: relative;
			margin-left: 10px;
			text-align: left;
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;#"Avenir";
			padding: 5px;
	}
	.margin-right-block {
			font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;#"Avenir";
			font-size: 14px;
			width: 25%; /* Change this percentage as needed */
			max-width: 256px; /* Optional: Maximum width */
			position: relative;
			text-align: left;
			padding: 10px;  /* Optional: Adds padding inside the caption */
	}

	img {
			max-width: 100%; /* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
	}
	.my-video {
			max-width: 100%; /* Make sure it fits inside the container */
			height: auto;
			display: block;
			margin: auto;
	}
	/* Hide both video displays initially, will display based on JS detection */
  .vid-mobile, .vid-non-mobile { display: none; }

  /* Show the video content by default on non-mobile devices */
  .show-vid-mobile .vid-mobile { display: block; }
  .show-vid-non-mobile .vid-non-mobile { display: block; }

	a:link,a:visited
	{
		color: #0e7862; /*#1367a7;*/
		text-decoration: none;
	}
	a:hover {
		color: #24b597; /*#208799;*/
	}

	h1 {
		font-size: 18px;
		margin-top: 4px;
		margin-bottom: 10px;
	}

	table.header {
    font-weight: 300;
    font-size: 17px;
    flex-grow: 1;
		width: 70%;
    max-width: calc(100% - 290px); /* Adjust according to the width of .paper-code-tab */
	}
	table td, table td * {
	    vertical-align: middle;
	    position: relative;
	}
	table.paper-code-tab {
	    flex-shrink: 0;
	    margin-left: 8px;
	    margin-top: 8px;
	    padding: 0px 0px 0px 8px;
	    width: 290px;
	    height: 150px;
	}

	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	hr {
    height: 1px; /* Sets the height of the line to 1 pixel */
    border: none; /* Removes the default border */
    background-color: #DDD; /* Sets the line color to black */
  }

	div.hypothesis {
		width: 80%;
		background-color: #EEE;
		border: 1px solid black;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
		font-family: Courier;
		font-size: 18px;
		text-align: center;
		margin: auto;
		padding: 16px 16px 16px 16px;
	}

	div.citation {
    font-size: 0.8em;
    background-color:#fff;
    padding: 10px;
		height: 200px;
  }

	.fade-in-inline {
		position: absolute;
		text-align: center;
		margin: auto;
		-webkit-mask-image: linear-gradient(to right,
																			transparent 0%,
																			transparent 40%,
																			black 50%,
																			black 90%,
																			transparent 100%);
		mask-image: linear-gradient(to right,
																transparent 0%,
																transparent 40%,
																black 50%,
																black 90%,
																transparent 100%);
		-webkit-mask-size: 8000% 100%;
		mask-size: 8000% 100%;
		animation-name: sweepMask;
		animation-duration: 4s;
		animation-iteration-count: infinite;
		animation-timing-function: linear;
		animation-delay: -1s;
	}

	.fade-in2-inline {
			animation-delay: 1s;
	}

	.inline-div {
			position: relative;
	    display: inline-block; /* Makes both the div and paragraph inline-block elements */
	    vertical-align: top; /* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
	    width: 50px; /* Optional: Adds space between the div and the paragraph */
	}

</style>

	  <title>LLMs for Transaction Graph Pattern Detection</title>
      <meta property="og:title" content="The Platonic Representation Hypothesis" />
			<meta charset="UTF-8">
  </head>

  <body>

		<div class="content-margin-container">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
						<table class="header" align=left>
								<tr>
									<td colspan=4>
										<span style="font-size: 32px; font-family: 'Courier New', Courier, monospace; /* Adds fallbacks */">LLMs for Transaction Graph Pattern Detection</span>
									</td>
								</tr>
								<tr>
										<td align=left>
												<span style="font-size:17px"><a href="your_website">Olivia Han</a></span>
										</td>
										<td align=left>
												<span style="font-size:17px"><a href="your_partner's_website">Eghosa Ohenhen</a></span>
										</td>
										<td align=left>
												<span style="font-size:17px"><a href="your_partner's_website">Jaclyn Thi</a></span>
										</td>
								<tr>
									<td colspan=4 align=left><span style="font-size:18px">Final project for 6.7960, MIT</span></td>
								</tr>
						</table>
					</div>
					<div class="margin-right-block">
					</div>
		</div>

		<div class="content-margin-container" id="intro">
				<div class="margin-left-block">
          <!-- table of contents here -->
          <div style="position:fixed; max-width:inherit; top:max(20%,120px)">
              <b style="font-size:16px">Outline</b><br><br>
              <a href="#intro">Introduction</a><br><br>
              <a href="#does_x_do_y">Does X do Y?</a><br><br>
              <a href="#implications_and_limitations">Implications and limitations</a><br><br>
          </div>
				</div>
		    <!-- <div class="main-content-block">
            <img src="./images/your_image_here.png" width=512px/> -->
		    <!-- </div> -->
		    <!-- <div class="margin-right-block">
						Caption for the image.
		    </div> -->
		</div>

    <div class="content-margin-container" id="intro">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
				<h1>Introduction</h1>
					<h2>Motivation</h2>
					<p>Designing systems to detect anomalies in complex relational data while remaining interpretable
			 is a key challenge in AI. A particularly important domain for this is financial transaction
			monitoring, where missed anomalies can facilitate fraud and false alarms can disrupt normal
			   activity. Detecting such behavior is inherently a graph problem, as illicit funds follow structured
			    patterns across accounts and intermediaries. Graph-based methods like GNNs achieve strong predictive
				 performance but are typically opaque, offering little human-interpretable insight into why a transaction
				  was flagged, and require extensive labeled data and infrastructure to train and deploy. As such,
				   Large Language Models (LLMs) provide a potential alternative way to reason over graph-structured
				    financial data.</p>
					<h2>Background and Related Work</h2>
						<p>Traditional graph-based approaches, including Graph Neural Networks (GNNs), learn latent representations to flag suspicious patterns and have demonstrated strong performance across various fraud detection tasks. Yet, these models are typically opaque, offering limited interpretability and little insight into why a transaction was flagged. This limitation has motivated a shift toward using Large Language Models (LLMs) as reasoning engines over graph-structured financial data. Synthetic AML benchmarks, such as the IBM anti–money laundering dataset, simulate canonical laundering typologies—including fan-in, fan-out, gather-scatter, scatter-gather, simple cycle, random, bipartite, and stack—which provide labeled transaction graphs in a domain where real, sensitive data are scarce (Altman et al., 2023). These typologies also form the pattern vocabulary used in recent LLM-based AML experiments.</p>
						<p>LLMs offer a promising alternative for reasoning over transaction graphs. Pirmorad (2025) demonstrates that serializing local k-hop neighborhoods around candidate transactions into text allows a general-purpose LLM to emulate an investigator’s reasoning: assessing suspiciousness and producing natural-language justifications. This approach enables LLMs to act as interpretable “reasoning heads,” combining structural graph signals with rich prior knowledge. However, applying LLMs naively to every candidate transaction is computationally expensive, and their tendency to hallucinate—producing plausible but unsupported explanations—poses a major risk in high-stakes domains like AML. Moreover, large graphs often exceed context limits, forcing LLM reasoning to focus on local subgraphs and potentially missing broader, global patterns.</p>
						<p>To address these challenges, recent work has explored multi-agent LLM reasoning frameworks. Hu et al. (2024) introduce a system in which multiple specialized LLM agents jointly reason over subgraph-centric tasks, aggregating their partial results to produce a final decision. This distributed approach reduces the computational burden on any single model and improves robustness through ensemble-like consensus, though it introduces additional orchestration complexity.</p>
						<p>Complementary to this, the teacher–student paradigm offers a way to combine the strengths of large, expressive LLMs with the efficiency of smaller models. Knowledge distillation (Hinton et al., 2015) allows a compact student model to learn both the outputs and intermediate reasoning traces of a teacher. Hsieh et al. (2023) demonstrate that chain-of-thought reasoning from very large models can be distilled into smaller LLMs with minimal loss in performance, effectively transferring both answers and explanation styles.<br>
						<p>Our work sits at the intersection of these trends. We adopt LLM-based graph reasoning for AML (Pirmorad, 2025), specialize multiple teacher agents as pattern experts in a multi-agent framework (Hu et al., 2024), and distill their judgments into a single, compact student model using supervised distillation techniques inspired by Hinton et al. (2015) and Hsieh et al. (2023). This design aims to balance interpretability, accuracy, and computational efficiency in high-stakes AML reasoning.</p>
					<h2>Goals</h2>
						<p>In this project, we investigate whether a smaller student LLM can learn pattern-aware AML reasoning by distilling knowledge from larger, pattern-specialized teacher LLMs. We focus on two accepted laundering typologies—fan-in and fan-out—using a transactional graph derived from a realistic AML benchmark, aiming to show that this approach can extend to other patterns. For each typology, a teacher LLM acts as a specialist, producing structured judgments (suspicious/not suspicious, pattern label, and explanation) for k-hop subgraphs around candidate transactions. We then fine-tune a compact student model to imitate these teachers via supervised distillation. Our key questions are: (1) Can a small student approximate the pattern-level judgments of larger teachers? and (2) How do factors like teacher data volume, neighborhood radius k, number of teachers, and inclusion of teacher rationales affect student performance and interpretability? This study explores the feasibility of scalable, explainable AML detectors distilled from expert LLMs.</p>
		    </div>
		    <div class="margin-right-block">
						Margin note that clarifies some detail #main-content-block for intro section.
		    </div>
		</div>

		<div class="content-margin-container" id="does_x_do_y">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
					<h1>Does X do Y?</h1>
				  It is well known that Y does Y. And this has raised the question does X do Y? Because if Y does Y then it stands to reason that X does Y.
          But we cannot answer this until we realize the Z implies Y and X can be linked to Z.<br><br>

          Now let's write some math!<br>
          <center>
            <math xmlns="http://www.w3.org/1998/Math/MathML">
              <mrow>
                <mrow>
                  <mo>&#x2202;</mo>
                  <mi>y</mi>
                </mrow>
                <mo>/</mo>
                <mrow>
                  <mo>&#x2202;</mo>
                  <mi>x</mi>
                </mrow>
              </mrow>
              <mo>=</mo>
              <mi>x</mi>
            </math>
          </center>
          <br>
          It's probably best to ask an LLM to help do the web
          formatting for math. You can tell it "convert this latex equation into MathML: $$\frac{\partial dy}{\partial dx} = x$$"
          But it took me a few tries. So, if you get frustrated, you can embed an image of the equation, or use other packages for
          rendering equations on webpages.
		    </div>
		    <div class="margin-right-block" style="transform: translate(0%, -100%);"> <!-- you can move the margin notes up and down with translate -->
          Interestingly, Plato also asked if X does Y, in <a href="#ref_1">[1]</a>.
		    </div>
		</div>

		<div class="content-margin-container">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
            <h1>Another section</h1>
            In this section we embed a video:
						<video class='my-video' loop autoplay muted style="width: 725px">
								<source src="./images/mtsh.mp4" type="video/mp4">
						</video>
		    </div>
		    <div class="margin-right-block">
					A caption for the video could go here.
		    </div>
		</div>

		<div class="content-margin-container" id="implications_and_limitations">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
						<h1>Implications and limitations</h1>
						Let's end with some discussion of the implications and limitations.
		    </div>
		    <div class="margin-right-block">
		    </div>
		</div>

		<div class="content-margin-container" id="citations">
				<div class="margin-left-block">
				</div>
		    <div class="main-content-block">
						<div class='citation' id="references" style="height:auto"><br>
							<span style="font-size:16px">References:</span><br><br>
							<a id="ref_1"></a>[1] <a href="https://en.wikipedia.org/wiki/Allegory_of_the_cave">Allegory of the Cave</a>, Plato, c. 375 BC<br><br>
							<a id="ref_2"></a>[2] <a href="">A Human-Level AGI</a>, OpenAI, 2025<br><br>
						</div>
		    </div>
		    <div class="margin-right-block">
            <!-- margin notes for reference block here -->
		    </div>
		</div>

	</body>

</html>
